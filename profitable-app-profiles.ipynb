{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitable App Profiles\n",
    "### Hemanth Soni, June 2020\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction and Overview\n",
    "\n",
    "The goal of this project is to identify the most profitable app profiles in the store. This should help our agency identify where we should focus our development effort. In order to ensure only relevant data is analyzed, the characteristics of the agency need to be kept in mind:\n",
    "* Only builds free apps (no paid apps)\n",
    "* Only builds apps for the English-speaking world (no foreign-language apps)\n",
    "\n",
    "Typically, I wouldn't want to exclude data outside of this profile (as I may find that those excluded categories / formats are actually the most lucrative) but for the purposes of this exercise I'll take those constraints for granted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets\n",
    "\n",
    "First, I'm going to start by importing a few datasets. The tutorial I am following provides two:\n",
    "* [9660 Android apps](https://www.kaggle.com/lava18/google-play-store-apps)\n",
    "* [7195 iOS apps](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps)\n",
    "\n",
    "Separately, I was able to find a [third much larger dataset of Android apps on Kaggle](https://www.kaggle.com/gauthamp10/google-playstore-apps?select=Google-Playstore-Full.csv). It has the same fields available in the provided Android dataset, so I'm going to also include this in the analysis. The larger dataset should allow for more granular insights into the Android market. Unfortunately, a similar larger dataset couldn't be found for the Apple app store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "#The small Google dataset\n",
    "open_file = open('apps_datasets/google_small.csv', encoding='utf8')\n",
    "read_file = reader(open_file)\n",
    "googlesmall = list(read_file)\n",
    "googlesmall_header = googlesmall[0]\n",
    "googlesmall_table = googlesmall[1:]\n",
    "\n",
    "#The large Google dataset\n",
    "open_file = open('apps_datasets/google_large.csv', encoding='utf8')\n",
    "read_file = reader(open_file)\n",
    "googlelarge = list(read_file)\n",
    "googlelarge_header = googlelarge[0]\n",
    "googlelarge_table = googlelarge[1:]\n",
    "\n",
    "#The Apple dataset\n",
    "open_file = open('apps_datasets/apple.csv', encoding='utf8')\n",
    "read_file = reader(open_file)\n",
    "apple = list(read_file)\n",
    "apple_header = apple[0]\n",
    "apple_table = apple[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this data easier to explore, I first wrote a function that makes it easier to 'peek' into a dataset in a readable way. This function lets me print any number of rows from each of the datasets and get a view into the datasets total number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of first 5 rows in database\n",
      "\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "Number of columns = 13\n",
      "Number of rows = 10841\n",
      "----------------------------------------\n",
      "Overview of first 5 rows in database\n",
      "\n",
      "\n",
      "['App Name', 'Category', 'Rating', 'Reviews', 'Installs', 'Size', 'Price', 'Content Rating', 'Last Updated', 'Minimum Version', 'Latest Version', '', '', '', '']\n",
      "\n",
      "\n",
      "['DoorDash - Food Delivery', 'FOOD_AND_DRINK', '4.548561573', '305034', '5,000,000+', 'Varies with device', '0', 'Everyone', 'March 29, 2019', 'Varies with device', 'Varies with device', '', '', '', '']\n",
      "\n",
      "\n",
      "['TripAdvisor Hotels Flights Restaurants Attractions', 'TRAVEL_AND_LOCAL', '4.400671482', '1207922', '100,000,000+', 'Varies with device', '0', 'Everyone', 'March 29, 2019', 'Varies with device', 'Varies with device', '', '', '', '']\n",
      "\n",
      "\n",
      "['Peapod', 'SHOPPING', '3.656329393', '1967', '100,000+', '1.4M', '0', 'Everyone', 'September 20, 2018', '5.0 and up', '2.2.0', '', '', '', '']\n",
      "\n",
      "\n",
      "['foodpanda - Local Food Delivery', 'FOOD_AND_DRINK', '4.107232571', '389154', '10,000,000+', '16M', '0', 'Everyone', 'March 22, 2019', '4.2 and up', '4.18.2', '', '', '', '']\n",
      "\n",
      "\n",
      "Number of columns = 15\n",
      "Number of rows = 267052\n",
      "----------------------------------------\n",
      "Overview of first 5 rows in database\n",
      "\n",
      "\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "['529479190', 'Clash of Clans', '116476928', 'USD', '0.0', '2130805', '579', '4.5', '4.5', '9.24.12', '9+', 'Games', '38', '5', '18', '1']\n",
      "\n",
      "\n",
      "['420009108', 'Temple Run', '65921024', 'USD', '0.0', '1724546', '3842', '4.5', '4.0', '1.6.2', '9+', 'Games', '40', '5', '1', '1']\n",
      "\n",
      "\n",
      "Number of columns = 16\n",
      "Number of rows = 7197\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def explore_data (dataset, start, end, overview=True, hasHeader=True):\n",
    "    slice = dataset[start:end]\n",
    "    \n",
    "    print('Overview of first ' + str(end-start) + ' rows in database')\n",
    "    print('\\n')\n",
    "    \n",
    "    for each in slice:\n",
    "        print(each)\n",
    "        print('\\n')\n",
    "        \n",
    "    if overview == True:\n",
    "        if hasHeader == True:\n",
    "            print('Number of columns = ' + str(len(dataset[0])))\n",
    "            print('Number of rows = ' + str(len(dataset)-1))\n",
    "            print('-'*40)\n",
    "        else:\n",
    "            print('Number of columns = ' + str(len(dataset[0])))\n",
    "            print('Number of rows = ' + str(len(dataset)))\n",
    "            print('-'*40)\n",
    "            \n",
    "explore_data(googlesmall,0,5)\n",
    "explore_data(googlelarge,0,5)\n",
    "explore_data(apple,0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting blank columns\n",
    "\n",
    "From the above, we can see that the last four columns of the larger Google dataset are blank. The code below quickly runs through the database and deletes those four rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in googlelarge:\n",
    "    del each[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then check the database again to make sure I did this right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of first 5 rows in database\n",
      "\n",
      "\n",
      "['App Name', 'Category', 'Rating', 'Reviews', 'Installs', 'Size', 'Price', 'Content Rating', 'Last Updated', 'Minimum Version', 'Latest Version']\n",
      "\n",
      "\n",
      "['DoorDash - Food Delivery', 'FOOD_AND_DRINK', '4.548561573', '305034', '5,000,000+', 'Varies with device', '0', 'Everyone', 'March 29, 2019', 'Varies with device', 'Varies with device']\n",
      "\n",
      "\n",
      "['TripAdvisor Hotels Flights Restaurants Attractions', 'TRAVEL_AND_LOCAL', '4.400671482', '1207922', '100,000,000+', 'Varies with device', '0', 'Everyone', 'March 29, 2019', 'Varies with device', 'Varies with device']\n",
      "\n",
      "\n",
      "['Peapod', 'SHOPPING', '3.656329393', '1967', '100,000+', '1.4M', '0', 'Everyone', 'September 20, 2018', '5.0 and up', '2.2.0']\n",
      "\n",
      "\n",
      "['foodpanda - Local Food Delivery', 'FOOD_AND_DRINK', '4.107232571', '389154', '10,000,000+', '16M', '0', 'Everyone', 'March 22, 2019', '4.2 and up', '4.18.2']\n",
      "\n",
      "\n",
      "Number of columns = 11\n",
      "Number of rows = 267052\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "explore_data(googlelarge,0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking data integrity\n",
    "\n",
    "To start, we can run a simple test on the datasets to ensure that each row is complete (ie. has the same number of elements as the header). The code for this is below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run through each dataset and return a frequency table by the number of elements in each row\n",
    "\n",
    "errorBase = {}\n",
    "\n",
    "def rowCheck(dataset):\n",
    "    \n",
    "    errorBase = {}\n",
    "    headerCount = len(dataset[0])\n",
    "    \n",
    "    print('Expecting',headerCount,'rows.')\n",
    "    \n",
    "    for each in dataset:\n",
    "        rowCount = len(each)\n",
    "        if (rowCount < headerCount) and (rowCount not in errorBase):\n",
    "            errorBase[rowCount] = 1\n",
    "        elif (rowCount < headerCount) and (rowCount in errorBase):\n",
    "            errorBase[rowCount] += 1\n",
    "    \n",
    "    if len(errorBase) == 0:\n",
    "        print('No errors found')\n",
    "    else:\n",
    "        print(errorBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting 13 rows.\n",
      "{12: 1}\n",
      "Expecting 11 rows.\n",
      "No errors found\n",
      "Expecting 16 rows.\n",
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "rowCheck(googlesmall)\n",
    "rowCheck(googlelarge)\n",
    "rowCheck(apple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling in missing data point\n",
    "\n",
    "Based on the above, one row appears to be short two elements. This a known error in the data, as seen in this [discussion](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015). But for the purposes of the exercise, let's pretend we don't know the row number, so we need to dig through and find it. I'll do that with the code below, then fill in the missing data by finding the app in the Play Store and filling in the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The error row is 10473\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "rowCounter = 0\n",
    "\n",
    "for each in googlesmall:\n",
    "    if len(each) == 12:\n",
    "        print('The error row is',rowCounter)\n",
    "        break\n",
    "    \n",
    "    rowCounter += 1    \n",
    "\n",
    "# Finding the app based on the counter above.\n",
    "print(googlesmall[int(rowCounter)])\n",
    "\n",
    "# Printing another row that is known to be fine to understand where the issue lays.\n",
    "print(googlesmall[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing these two outputs, we can see that the \"category\" (index position 1) and the \"genre\" (index position 11) are missing in the error row. We can correct for this by adding it into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', 'LIFESTYLE', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', 'Lifestyle', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', 'LIFESTYLE', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', 'Lifestyle', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "Expecting 13 rows.\n",
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Adding in missing data (category and genre)\n",
    "# googlesmall[10473].insert(1,'LIFESTYLE') # commented out so that data isn't inserted in re-runs\n",
    "# googlesmall[10473].insert(9,'Lifestyle') # commented out so that data isn't inserted in re-runs\n",
    "\n",
    "# Comparing against a row known to be error-free to visually check\n",
    "print(googlesmall[10473])\n",
    "print(googlesmall[1])\n",
    "\n",
    "# Deleting blank element at index 10\n",
    "# googlesmall[10473].remove('') # commented out so that data isn't inserted in re-runs\n",
    "print(googlesmall[10473])\n",
    "\n",
    "# Confirming that error has been corrected\n",
    "rowCheck(googlesmall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuing data integrity check\n",
    "\n",
    "Next, we can check to make sure that the columns contain only the type of data expected. For example, the reviews column should only include numbers, no letters / phrases. We can do this by defining a function to check that an index number contains only the type of elements stated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elementCheck(database, index, var):\n",
    "    \n",
    "    counter = 1\n",
    "    errorCounter = 0\n",
    "    errorBase = []\n",
    "    \n",
    "    for each in database[1:]:\n",
    "        \n",
    "        # There's almost definitely a better way to do this, but the code below checks if setting the specified element to especified type works\n",
    "        try:\n",
    "            if isinstance(var(each[index]), var):\n",
    "                pass\n",
    "            \n",
    "        # If it doesn't, adds it to the error-checker database\n",
    "        except ValueError:\n",
    "            errorBase.append(counter)\n",
    "            errorCounter += 1\n",
    "        counter += 1\n",
    "    \n",
    "    print('This database has',errorCounter,'errors at index point',str(index)+'.')\n",
    "    \n",
    "    if len(errorBase) > 0:\n",
    "        print(errorBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small Google dataset check:\n",
      "This database has 0 errors at index point 2.\n",
      "This database has 0 errors at index point 3.\n",
      "\n",
      "Larger Google dataset check:\n",
      "This database has 17 errors at index point 2.\n",
      "[6942, 13505, 23458, 32230, 48439, 113152, 125480, 125481, 165231, 168915, 177166, 180372, 190760, 193870, 194166, 232812, 257774]\n",
      "This database has 13 errors at index point 3.\n",
      "[6942, 23458, 48439, 113152, 125481, 165231, 168915, 177166, 180372, 193870, 194166, 232812, 257774]\n",
      "\n",
      "Apple dataset check:\n",
      "This database has 0 errors at index point 0.\n",
      "This database has 0 errors at index point 2.\n",
      "This database has 0 errors at index point 4.\n",
      "This database has 0 errors at index point 5.\n",
      "This database has 0 errors at index point 6.\n",
      "This database has 0 errors at index point 7.\n",
      "This database has 0 errors at index point 8.\n"
     ]
    }
   ],
   "source": [
    "# A better way to do this error check would be to define a dictionary of elements and their correct type, but I'm lazy.\n",
    "# A better checker would also be able to account for some common data characteristics, like commas in numbers, or dollars for currency-denominated fields\n",
    "# Also, hecks for strings isn't actually useful, as everything is stored a string. So I'm only running this on columns where I am expecting only non-strings\n",
    "\n",
    "# Checking the smaller Google dataset\n",
    "print('Small Google dataset check:')\n",
    "elementCheck(googlesmall, 2, float)\n",
    "elementCheck(googlesmall, 3, int)\n",
    "print('')\n",
    "    \n",
    "# Checking the larger Google dataset\n",
    "print('Larger Google dataset check:')\n",
    "elementCheck(googlelarge, 2, float)\n",
    "elementCheck(googlelarge, 3, int)\n",
    "print('')\n",
    "\n",
    "# Checking the Apple dataset\n",
    "print('Apple dataset check:')\n",
    "elementCheck(apple, 0, int)\n",
    "elementCheck(apple, 2, int)\n",
    "elementCheck(apple, 4, float)\n",
    "elementCheck(apple, 5, int)\n",
    "elementCheck(apple, 6, int)\n",
    "elementCheck(apple, 7, float)\n",
    "elementCheck(apple, 8, float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can tell the larger Google dataset has some errors that need to be corrected. All of the index numbes that have an error on the third element also have an error on the second element, so I will start by printing some of the flagged indexes in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ELer Japanese - NHK News', ' Podcasts', ' Lessons', '', 'EDUCATION', '4.705075264', '1458', '100,000+', '9.5M', '0', 'Everyone']\n",
      "['Never have I ever 18+ ', ')', 'GAME_STRATEGY', '4', '6', '100+', '2.4M', '$0.99', 'Mature 17+', 'December 30, 2018', '4.0.3 and up']\n",
      "['Israel News', ' Channel 2 News', 'NEWS_AND_MAGAZINES', '3.857798815', '11976', '1,000,000+', 'Varies with device', '0', 'Everyone 10+', 'March 16, 2019', 'Varies with device']\n"
     ]
    }
   ],
   "source": [
    "print(googlelarge[6942])\n",
    "print(googlelarge[13505])\n",
    "print(googlelarge[23458])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, I can see these are genuine errors (incorrectly filled, with blank tags, etc.). Because the number of flagged errors is so small, I will just delete these rows from the dataset rather than attempting to fix them. The dataset as a whole will still provide sufficient value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorSet = [6942, 13505, 23458, 32230, 48439, 113152, 125480, 125481, 165231, 168915, 177166, 180372, 190760, 193870, 194166, 232812, 257774]\n",
    "\n",
    "# Reversing the errorset so that they get deleted from largest to smallest index (so that the index numbers don't change during deletion)\n",
    "errorSet.reverse()\n",
    "\n",
    "for each in errorSet:\n",
    "    del googlelarge[each]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then check the database for errors again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger Google dataset check:\n",
      "This database has 0 errors at index point 2.\n",
      "This database has 0 errors at index point 3.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Larger Google dataset check:')\n",
    "elementCheck(googlelarge, 2, float)\n",
    "elementCheck(googlelarge, 3, int)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! We now have 3 databases with proper rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicates\n",
    "\n",
    "Generally, it's a good idea to check for duplicates in the datasets, and remove them if they exist. We will do this as a two step process.\n",
    "1. Check if the database has duplicates\n",
    "2. Remove the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique apps: 7198\n",
      "Number of duplicate apps: 0\n",
      "\n",
      "Number of unique apps: 9661\n",
      "Number of duplicate apps: 1181\n",
      "\n",
      "There are 22629 duplicates in the larger Google database.\n"
     ]
    }
   ],
   "source": [
    "# Initiating lists\n",
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "\n",
    "# Function to check for duplicates\n",
    "def check_dupes(listname):\n",
    "    for each in listname:\n",
    "        name = each[0]\n",
    "        if name in unique_apps:\n",
    "            duplicate_apps.append(name)\n",
    "        else:\n",
    "            unique_apps.append(name)\n",
    "            \n",
    "    print('Number of unique apps:',len(unique_apps))\n",
    "    print('Number of duplicate apps:',len(duplicate_apps))\n",
    "    print('')\n",
    "    \n",
    "    del unique_apps[:]\n",
    "    del duplicate_apps[:]\n",
    "    \n",
    "# Checking each list for duplicates\n",
    "check_dupes(apple)\n",
    "check_dupes(googlesmall)\n",
    "\n",
    "# The check for the large database is disabled as my computer isn't strong enough to run it.\n",
    "\n",
    "# check_dupes(googlelarge)\n",
    "\n",
    "# This is likely because of a limitation of the code I wrote for checking for duplicates. The if statement checks a database that grows with every row of the database\n",
    "# It starts by checkin a database with 0 elements, then 1, then 2, then 3, etc. But for a large dataset it soon needs to check through a database of 100k+ rows\n",
    "# I don't know a better way to check for duplicates, but it looks like Kaggle does because the website says the dataset has 244407 unique apps\n",
    "\n",
    "if len(googlelarge) == 244407:\n",
    "    print('No duplicates the larger Google database')\n",
    "else:\n",
    "    print('There are',len(googlelarge)-244407,'duplicates in the larger Google database.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see that the Apple Store dataset doesn't have any duplicates for us to worry about, but the smaller Google Play Store dataset does, as does the larger Google Play Store dataset. We'll filter through and keep only the version of each app with the most reviews (as this suggests the most complete and up-to-date data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating dictionary to store highest-review-count-version of each app\n",
    "reviews_max = {}\n",
    "reviews_max_l = {}\n",
    "\n",
    "# Iterating through smaller Google dataset\n",
    "for each in googlesmall[1:]:\n",
    "    name = each[0]\n",
    "    n_reviews = float(each[3])\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "\n",
    "# Iterating through larger Google dataset\n",
    "for each in googlelarge[1:]:\n",
    "    name = each[0]\n",
    "    n_reviews_l = float(each[3])\n",
    "    \n",
    "    if name in reviews_max_l and reviews_max_l[name] < n_reviews_l:\n",
    "        reviews_max_l[name] = n_reviews_l\n",
    "    elif name not in reviews_max_l:\n",
    "        reviews_max_l[name] = n_reviews_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can check for errors by comparing the expected length of the dictionary vs. the actual length of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The dictionary is the expected size: 9660 entries.\n",
      "Success! The dictionary is the expected size: 244392 entries.\n"
     ]
    }
   ],
   "source": [
    "if int(len(googlesmall[1:])-1181) == len(reviews_max):\n",
    "    print ('Success! The dictionary is the expected size:',len(reviews_max),'entries.')\n",
    "else:\n",
    "    print ('Something is wrong.',int(len(googlesmall[1:])-1181),'entries were expected, but',len(reviews_max),'were recorded.')\n",
    "\n",
    "if int(len(googlelarge[1:])-22629-13-1) == len(reviews_max_l):\n",
    "    print ('Success! The dictionary is the expected size:',len(reviews_max_l),'entries.')\n",
    "else:\n",
    "    print ('Something is wrong.',int(len(googlelarge[1:])-22629-13-1),'entries were expected, but',len(reviews_max_l),'were recorded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll use this dictionary to remove the duplicates, keeping the entry version with the greatest number of reviews and entering them into a new table, 'googlesmall_nodupes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating new lists\n",
    "googlesmall_nodupes = []\n",
    "already_added = []\n",
    "googlelarge_nodupes = []\n",
    "already_added_l = []\n",
    "\n",
    "# Filling out new lists\n",
    "for each in googlesmall[1:]:\n",
    "    name = each[0]\n",
    "    n_reviews = float(each[3])\n",
    "    \n",
    "    if reviews_max[name] >= n_reviews and name not in already_added:\n",
    "        googlesmall_nodupes.append(each)\n",
    "        already_added.append(name)\n",
    "\n",
    "# The code below takes forever to run. Troubleshoot here.\n",
    "# for each in googlelarge[1:]:\n",
    "#     name = each[0]\n",
    "#     n_reviews_l = float(each[3])\n",
    "#     \n",
    "#     if reviews_max_l[name] >= n_reviews_l and name not in already_added_l:\n",
    "#         googlelarge_nodupes.append(each)\n",
    "#         already_added_l.append(name)\n",
    "#     print('Cycle complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing non-English apps\n",
    "\n",
    "To filter out non-English apps, I'll filter the database for any non-English characters (beyond ASCII code 127)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to check if the passed phrase is fully English\n",
    "def isEnglish(phrase):\n",
    "    \n",
    "    non_english = 0\n",
    "    \n",
    "    for each in phrase:\n",
    "        if ord(each) > 127:\n",
    "            non_english += 1\n",
    "        \n",
    "        if non_english >= 3:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Testing this function against several examples\n",
    "# print(isEnglish('Instachat 😜'))\n",
    "# print(isEnglish('Instagram'))\n",
    "# print(isEnglish('爱奇艺PPS -《欢乐颂2》电视剧热播'))\n",
    "# print(isEnglish('Docs To Go™ Free Office Suite'))\n",
    "\n",
    "googlesmall_nodupes_eng = []\n",
    "googlelarge_eng = []\n",
    "apple_eng = []\n",
    "\n",
    "for each in googlesmall_nodupes:\n",
    "    name = each[0]\n",
    "    if isEnglish(name):\n",
    "        googlesmall_nodupes_eng.append(each)\n",
    "        \n",
    "for each in googlelarge:\n",
    "    name = each[0]\n",
    "    if isEnglish(name):\n",
    "        googlelarge_eng.append(each)\n",
    "\n",
    "for each in apple:\n",
    "    name = each[1]\n",
    "    if isEnglish(name):\n",
    "        apple_eng.append(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing paid apps\n",
    "\n",
    "Because the agency is only concerned with free apps, we can use a similar mechanism to the above to remove any apps that are paid. This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8847\n",
      "3203\n"
     ]
    }
   ],
   "source": [
    "# Initializing final lists for each dataset\n",
    "googlesmall_final = []\n",
    "googlelarge_final = []\n",
    "apple_final = []\n",
    "\n",
    "for each in googlesmall_nodupes_eng:\n",
    "    price = each[7]\n",
    "    if price == '0':\n",
    "        googlesmall_final.append(each)\n",
    "        \n",
    "for each in apple_eng:\n",
    "    price = each[4]\n",
    "    if price == '0.0':\n",
    "        apple_final.append(each)\n",
    "\n",
    "print(len(googlesmall_final))\n",
    "print(len(apple_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data\n",
    "\n",
    "Now that I have my cleaned datasets, I can begin the analysis. To do this in the most useful way possible, I have to consider the launch strategy of the agency, which is as follows:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, develop it further.\n",
    "3. If the app is profitable after six months, build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "The agency has already determined through previous analysis that there is a direct and linear correlation between the number of installs and the revenue generated by the app; thus to maximize profit our goal is to maximize installations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common App Profiles\n",
    "\n",
    "Given that the agency's target is to launch the same app on multiple stores, I can start by identifying the types of applications that are successful in both the Google Play Store and the Apple iOS store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to build a frequency table out of any dataset for a given index number\n",
    "\n",
    "def freq_table(dataset, index):\n",
    "    table = {}\n",
    "    total = 0\n",
    "\n",
    "    for each in dataset:\n",
    "\n",
    "        # Extracting the value at the given index number\n",
    "        value = each[index]\n",
    "\n",
    "        # Checking if value exists in table and either adding to the count or creating the entry\n",
    "        if value in table:\n",
    "            table[value] += 1\n",
    "        else:\n",
    "            table[value] = 1\n",
    "\n",
    "        # Increasing the total count by 1\n",
    "        total += 1\n",
    "\n",
    "        # Initializing a new table to return figures in percentages\n",
    "        table_percent = {}\n",
    "\n",
    "        for each in table:\n",
    "            percentage = table[each] / total * 100\n",
    "            table_percent[each] = round(percentage,2)\n",
    "\n",
    "    return table_percent\n",
    "\n",
    "# Creating a function that sorts and then prints a given input frequency table\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Table, Category\n",
      "FAMILY : 18.48\n",
      "GAME : 9.85\n",
      "TOOLS : 8.43\n",
      "BUSINESS : 4.6\n",
      "PRODUCTIVITY : 3.9\n",
      "LIFESTYLE : 3.9\n",
      "FINANCE : 3.71\n",
      "MEDICAL : 3.53\n",
      "SPORTS : 3.39\n",
      "PERSONALIZATION : 3.32\n",
      "COMMUNICATION : 3.23\n",
      "HEALTH_AND_FITNESS : 3.09\n",
      "PHOTOGRAPHY : 2.95\n",
      "NEWS_AND_MAGAZINES : 2.8\n",
      "SOCIAL : 2.67\n",
      "TRAVEL_AND_LOCAL : 2.34\n",
      "SHOPPING : 2.25\n",
      "BOOKS_AND_REFERENCE : 2.14\n",
      "DATING : 1.87\n",
      "VIDEO_PLAYERS : 1.79\n",
      "MAPS_AND_NAVIGATION : 1.39\n",
      "EDUCATION : 1.29\n",
      "FOOD_AND_DRINK : 1.24\n",
      "ENTERTAINMENT : 1.13\n",
      "LIBRARIES_AND_DEMO : 0.94\n",
      "AUTO_AND_VEHICLES : 0.93\n",
      "HOUSE_AND_HOME : 0.81\n",
      "WEATHER : 0.79\n",
      "EVENTS : 0.71\n",
      "ART_AND_DESIGN : 0.68\n",
      "PARENTING : 0.66\n",
      "COMICS : 0.61\n",
      "BEAUTY : 0.6\n",
      " \n",
      "Google Table, Genres\n",
      "Tools : 8.42\n",
      "Entertainment : 6.08\n",
      "Education : 5.36\n",
      "Business : 4.6\n",
      "Productivity : 3.9\n",
      "Lifestyle : 3.89\n",
      "Finance : 3.71\n",
      "Medical : 3.53\n",
      "Sports : 3.46\n",
      "Personalization : 3.32\n",
      "Communication : 3.23\n",
      "Action : 3.1\n",
      "Health & Fitness : 3.09\n",
      "Photography : 2.95\n",
      "News & Magazines : 2.8\n",
      "Social : 2.67\n",
      "Travel & Local : 2.33\n",
      "Shopping : 2.25\n",
      "Books & Reference : 2.14\n",
      "Simulation : 2.05\n",
      "Dating : 1.87\n",
      "Arcade : 1.84\n",
      "Video Players & Editors : 1.77\n",
      "Casual : 1.76\n",
      "Maps & Navigation : 1.39\n",
      "Food & Drink : 1.24\n",
      "Puzzle : 1.13\n",
      "Racing : 0.99\n",
      "Role Playing : 0.94\n",
      "Libraries & Demo : 0.94\n",
      "Auto & Vehicles : 0.93\n",
      "Strategy : 0.92\n",
      "House & Home : 0.81\n",
      "Weather : 0.79\n",
      "Events : 0.71\n",
      "Adventure : 0.67\n",
      "Comics : 0.6\n",
      "Beauty : 0.6\n",
      "Art & Design : 0.6\n",
      "Parenting : 0.5\n",
      "Card : 0.45\n",
      "Trivia : 0.42\n",
      "Casino : 0.42\n",
      "Educational;Education : 0.4\n",
      "Educational : 0.37\n",
      "Board : 0.37\n",
      "Education;Education : 0.34\n",
      "Word : 0.26\n",
      "Casual;Pretend Play : 0.24\n",
      "Music : 0.2\n",
      "Racing;Action & Adventure : 0.17\n",
      "Puzzle;Brain Games : 0.17\n",
      "Entertainment;Music & Video : 0.17\n",
      "Casual;Brain Games : 0.14\n",
      "Casual;Action & Adventure : 0.14\n",
      "Arcade;Action & Adventure : 0.12\n",
      "Action;Action & Adventure : 0.1\n",
      "Educational;Pretend Play : 0.09\n",
      "Board;Brain Games : 0.09\n",
      "Simulation;Action & Adventure : 0.08\n",
      "Parenting;Education : 0.08\n",
      "Entertainment;Brain Games : 0.08\n",
      "Parenting;Music & Video : 0.07\n",
      "Educational;Brain Games : 0.07\n",
      "Casual;Creativity : 0.07\n",
      "Art & Design;Creativity : 0.07\n",
      "Education;Pretend Play : 0.06\n",
      "Role Playing;Pretend Play : 0.05\n",
      "Education;Creativity : 0.05\n",
      "Role Playing;Action & Adventure : 0.03\n",
      "Puzzle;Action & Adventure : 0.03\n",
      "Entertainment;Creativity : 0.03\n",
      "Entertainment;Action & Adventure : 0.03\n",
      "Educational;Creativity : 0.03\n",
      "Educational;Action & Adventure : 0.03\n",
      "Education;Music & Video : 0.03\n",
      "Education;Brain Games : 0.03\n",
      "Education;Action & Adventure : 0.03\n",
      "Adventure;Action & Adventure : 0.03\n",
      "Video Players & Editors;Music & Video : 0.02\n",
      "Sports;Action & Adventure : 0.02\n",
      "Simulation;Pretend Play : 0.02\n",
      "Puzzle;Creativity : 0.02\n",
      "Music;Music & Video : 0.02\n",
      "Entertainment;Pretend Play : 0.02\n",
      "Casual;Education : 0.02\n",
      "Board;Action & Adventure : 0.02\n",
      "Video Players & Editors;Creativity : 0.01\n",
      "Trivia;Education : 0.01\n",
      "Travel & Local;Action & Adventure : 0.01\n",
      "Tools;Education : 0.01\n",
      "Strategy;Education : 0.01\n",
      "Strategy;Creativity : 0.01\n",
      "Strategy;Action & Adventure : 0.01\n",
      "Simulation;Education : 0.01\n",
      "Role Playing;Brain Games : 0.01\n",
      "Racing;Pretend Play : 0.01\n",
      "Puzzle;Education : 0.01\n",
      "Parenting;Brain Games : 0.01\n",
      "Music & Audio;Music & Video : 0.01\n",
      "Lifestyle;Pretend Play : 0.01\n",
      "Lifestyle;Education : 0.01\n",
      "Health & Fitness;Education : 0.01\n",
      "Health & Fitness;Action & Adventure : 0.01\n",
      "Entertainment;Education : 0.01\n",
      "Communication;Creativity : 0.01\n",
      "Comics;Creativity : 0.01\n",
      "Casual;Music & Video : 0.01\n",
      "Card;Action & Adventure : 0.01\n",
      "Books & Reference;Education : 0.01\n",
      "Art & Design;Pretend Play : 0.01\n",
      "Art & Design;Action & Adventure : 0.01\n",
      "Arcade;Pretend Play : 0.01\n",
      "Adventure;Education : 0.01\n",
      " \n",
      "Apple Table, Genre\n",
      "Games : 58.26\n",
      "Entertainment : 7.84\n",
      "Photo & Video : 5.0\n",
      "Education : 3.68\n",
      "Social Networking : 3.31\n",
      "Shopping : 2.59\n",
      "Utilities : 2.47\n",
      "Sports : 2.15\n",
      "Music : 2.06\n",
      "Health & Fitness : 2.03\n",
      "Productivity : 1.75\n",
      "Lifestyle : 1.56\n",
      "News : 1.34\n",
      "Travel : 1.25\n",
      "Finance : 1.09\n",
      "Weather : 0.87\n",
      "Food & Drink : 0.81\n",
      "Reference : 0.53\n",
      "Business : 0.53\n",
      "Book : 0.37\n",
      "Navigation : 0.19\n",
      "Medical : 0.19\n",
      "Catalogs : 0.12\n"
     ]
    }
   ],
   "source": [
    "# Creating tables for each of the app stores\n",
    "\n",
    "print('Google Table, Category')\n",
    "display_table(googlesmall_final,1)\n",
    "print(' ')\n",
    "print('Google Table, Genres')\n",
    "display_table(googlesmall_final,9)\n",
    "print(' ')\n",
    "print('Apple Table, Genre')\n",
    "display_table(apple_final,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this quick analysis, we can see that on the Google store, apps are generally a bit fragmented across various categories, with about 20% to family apps (which are mostly kids games), another 10% to games, and the remainder to more productivity-focused applications across various categories.\n",
    "\n",
    "In the Apple store on other hand, Games are the clearly dominant category with ~60% of apps falling within that category, and another 8% to entertainment. This might indicate that focusing on building games is a decent strategy, but is no means conclusive since the number of apps in a given genre doesn't necessary correlate to the total number of installs for apps in that genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Installed Apps\n",
    "\n",
    "The previous calculations show us the genres with the most applications; I will now focus on identifying which genres have the most user installs. This data is given for the Google dataset, but the Apple Store data is missing install counts; I can use reviews a proxy for that data. While imperfect (as its possible apps in certain categories more frequently prompt users to leave reviews than others) it is likely still directionally informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Networking : 71548.34905660378\n",
      "Photo & Video : 28441.54375\n",
      "Games : 22886.36709539121\n",
      "Music : 57326.530303030304\n",
      "Reference : 79350.4705882353\n",
      "Health & Fitness : 23298.015384615384\n",
      "Weather : 52279.892857142855\n",
      "Utilities : 19156.493670886077\n",
      "Travel : 28243.8\n",
      "Shopping : 27230.734939759037\n",
      "News : 21248.023255813954\n",
      "Navigation : 86090.33333333333\n",
      "Lifestyle : 16815.48\n",
      "Entertainment : 14195.358565737051\n",
      "Food & Drink : 33333.92307692308\n",
      "Sports : 23008.898550724636\n",
      "Book : 46384.916666666664\n",
      "Finance : 32367.02857142857\n",
      "Education : 7003.983050847458\n",
      "Productivity : 21028.410714285714\n",
      "Business : 7491.117647058823\n",
      "Catalogs : 4004.0\n",
      "Medical : 612.0\n"
     ]
    }
   ],
   "source": [
    "apple_genres = freq_table(apple_final, 11)\n",
    "\n",
    "for genre in apple_genres:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    \n",
    "    for each in apple_final:\n",
    "        app_genre = each[11]\n",
    "        if app_genre == genre:\n",
    "            ratings = float(each[5])\n",
    "            total += ratings\n",
    "            len_genre += 1\n",
    "    \n",
    "    average = total / len_genre\n",
    "    print(genre,':', average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, we can see that the most frequently rated (and presumably used) are in the navigation, social networking, reference, and music categories. It is still too early to suggest that these profiles make sense to focus on, as the concentration of usage isn't clear from the above summary table. For example, we know that the vast majority of apps are in the games category from earlier analysis, but they aren't in the top 3 most rated. Which suggests that each game on average likely receives less downloads than the average app in other categories.\n",
    "\n",
    "It'll be important to recalculate the averages above to exclude the anomalies at the top of the charts: A few mega-apps such as Spotify, Google Maps, and Facebook/Instagram are likely heavily skewing the results in specific categories. I would likely want to remove the top X apps in any given category to account for this, but will leave that for later.\n",
    "\n",
    "For now, I'll repeat the process above for the Google Play dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ART_AND_DESIGN : 1905351.6666666667\n",
      "AUTO_AND_VEHICLES : 647317.8170731707\n",
      "BEAUTY : 513151.88679245283\n",
      "BOOKS_AND_REFERENCE : 8814199.78835979\n",
      "BUSINESS : 1712290.1474201474\n",
      "COMICS : 832613.8888888889\n",
      "COMMUNICATION : 38590581.08741259\n",
      "DATING : 854028.8303030303\n",
      "EDUCATION : 3082017.543859649\n",
      "ENTERTAINMENT : 21134600.0\n",
      "EVENTS : 253542.22222222222\n",
      "FINANCE : 1387692.475609756\n",
      "FOOD_AND_DRINK : 1924897.7363636363\n",
      "HEALTH_AND_FITNESS : 4188821.9853479853\n",
      "HOUSE_AND_HOME : 1341839.736111111\n",
      "LIBRARIES_AND_DEMO : 638503.734939759\n",
      "LIFESTYLE : 1441969.3594202898\n",
      "GAME : 15795366.762342136\n",
      "FAMILY : 2691618.159021407\n",
      "MEDICAL : 120616.48717948717\n",
      "SOCIAL : 23253652.127118643\n",
      "SHOPPING : 7036877.311557789\n",
      "PHOTOGRAPHY : 17805627.643678162\n",
      "SPORTS : 3650602.276666667\n",
      "TRAVEL_AND_LOCAL : 13984077.710144928\n",
      "TOOLS : 10723898.758713137\n",
      "PERSONALIZATION : 5201482.6122448975\n",
      "PRODUCTIVITY : 16787331.344927534\n",
      "PARENTING : 542603.6206896552\n",
      "WEATHER : 5145550.285714285\n",
      "VIDEO_PLAYERS : 24852732.40506329\n",
      "NEWS_AND_MAGAZINES : 9549178.467741935\n",
      "MAPS_AND_NAVIGATION : 4049274.6341463416\n"
     ]
    }
   ],
   "source": [
    "google_cats = freq_table(googlesmall_final, 1)\n",
    "\n",
    "for genre in google_cats:\n",
    "    total = 0\n",
    "    len_cats = 0\n",
    "    for each in googlesmall_final:\n",
    "        app_cat = each[1]\n",
    "        if app_cat == genre:\n",
    "            installs = each[5]\n",
    "            installs = installs.replace(',','')\n",
    "            installs = installs.replace('+','')\n",
    "            installs = int(installs)\n",
    "            \n",
    "            total += installs\n",
    "            len_cats += 1\n",
    "        \n",
    "    average = total / len_cats\n",
    "    print(genre,':', average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, communications apps have the most installs, but as in the apps store, this is likely heavily skewed by a few mega-apps such as Whatsapp. To address this, I will build a function that removes the top 10 apps from consideration in any category, and then provides the same summary statistics shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the reviews to integers instead of strings so that they will sort properly\n",
    "\n",
    "for each in googlesmall_final:\n",
    "    each[3] = int(each[3])\n",
    "    \n",
    "for each in apple_final:\n",
    "    each[5] = int(each[5])\n",
    "    \n",
    "# Sorting each dataset\n",
    "\n",
    "def googleRanking(elem):\n",
    "    return elem[3] # by review count\n",
    "\n",
    "googlesmall_final.sort(key=googleRanking, reverse=True)\n",
    "\n",
    "def appleRanking(elem):\n",
    "    return elem[5]\n",
    "\n",
    "apple_final.sort(key=appleRanking, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will check to see if this worked by exploring the first few apps in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explore_data(apple_final,0,5)\n",
    "explore_data(googlesmall_final,0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the two datasets are sorted, I can write a new function to assess each category, excluding the first 10 responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social Networking : 13521\n",
      "Photo & Video : 6763\n",
      "Games : 17766\n",
      "Music : 5999\n",
      "Reference : 225\n",
      "Health & Fitness : 2395\n",
      "Weather : 379\n",
      "Utilities : 3895\n",
      "Travel : 1127\n",
      "Shopping : 8791\n",
      "News : 1016\n",
      "Navigation : 0\n",
      "Lifestyle : 1275\n",
      "Entertainment : 7308\n",
      "Food & Drink : 338\n",
      "Sports : 5459\n",
      "Book : 0\n",
      "Finance : 3417\n",
      "Education : 1904\n",
      "Productivity : 6251\n",
      "Business : 116\n",
      "Catalogs : 0\n",
      "Medical : 0\n",
      "\n",
      "SOCIAL : 4185855\n",
      "COMMUNICATION : 18310860\n",
      "GAME : 12236239\n",
      "TOOLS : 6032209\n",
      "VIDEO_PLAYERS : 11814757\n",
      "NEWS_AND_MAGAZINES : 1061275\n",
      "PHOTOGRAPHY : 10525934\n",
      "FAMILY : 2287948\n",
      "TRAVEL_AND_LOCAL : 2244947\n",
      "PERSONALIZATION : 2140258\n",
      "MAPS_AND_NAVIGATION : 1203746\n",
      "ENTERTAINMENT : 5834600\n",
      "EDUCATION : 1625877\n",
      "SHOPPING : 3519289\n",
      "PRODUCTIVITY : 9106171\n",
      "HEALTH_AND_FITNESS : 1551459\n",
      "SPORTS : 2050602\n",
      "BOOKS_AND_REFERENCE : 1142242\n",
      "LIFESTYLE : 891244\n",
      "WEATHER : 1431264\n",
      "FINANCE : 686472\n",
      "BUSINESS : 643494\n",
      "FOOD_AND_DRINK : 1106715\n",
      "COMICS : 184465\n",
      "PARENTING : 170189\n",
      "DATING : 363119\n",
      "HOUSE_AND_HOME : 411284\n",
      "LIBRARIES_AND_DEMO : 96335\n",
      "ART_AND_DESIGN : 130351\n",
      "AUTO_AND_VEHICLES : 159512\n",
      "MEDICAL : 62924\n",
      "BEAUTY : 88623\n",
      "EVENTS : 18621\n"
     ]
    }
   ],
   "source": [
    "apple_genres = freq_table(apple_final, 11)\n",
    "\n",
    "for genre in apple_genres:\n",
    "    total = 0\n",
    "    len_genre = 0\n",
    "    excludetop = 10\n",
    "    \n",
    "    for each in apple_final:\n",
    "        app_genre = each[11]\n",
    "        if app_genre == genre and len_genre >= excludetop:\n",
    "            ratings = each[5]\n",
    "            total += ratings\n",
    "            len_genre += 1\n",
    "        elif app_genre == genre and len_genre < excludetop:\n",
    "            len_genre += 1\n",
    "\n",
    "    average = total / len_genre\n",
    "    print(genre,':', int(average))\n",
    "\n",
    "print('')\n",
    "\n",
    "google_cats = freq_table(googlesmall_final, 1)\n",
    "\n",
    "for genre in google_cats:\n",
    "    total = 0\n",
    "    len_cats = 0\n",
    "    excludetop = 10\n",
    "        \n",
    "    for each in googlesmall_final:\n",
    "        app_cat = each[1]\n",
    "        if app_cat == genre and len_cats >= excludetop:\n",
    "            installs = each[5]\n",
    "            installs = installs.replace(',','')\n",
    "            installs = installs.replace('+','')\n",
    "            installs = int(installs)\n",
    "            total += installs\n",
    "            len_cats += 1\n",
    "        if app_cat == genre and len_cats < excludetop:\n",
    "            len_cats += 1\n",
    "        \n",
    "    average = total / len_cats\n",
    "    print(genre,':', int(average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By removing the most popular apps, a slightly different narrative emerges. Specifically, in the Apple store we can see that while originally it may have appeared attractive with a large number of average installs (proxied by reviews), the user activity was concentrated in a limited number of apps (less than 10). Given the presence of Waze, Google Maps, etc., in that market, I recommend staying away from the Navigation category.\n",
    "\n",
    "The game category seems quite competitive: even after excluding the top 10 in the category, the average user activity / reviews for games was much higher than any other category in the Apple store, and quite high in the game store as well. As we know from previous analysis, this is also the category with a significant amount of developer activity (with a large number of apps falling into this category) in the Apple store. To know whether it is a good idea or not to participate in this category is a strategic choice for the agency to make: do we believe we can be competitive (ie. do we have top-tier developers, designers, and ideas?).\n",
    "\n",
    "The productivity category appears to be promising as well, with a large user base that is not concentrated in only a few players across both app stores. We can print out some of the top apps in these categories across each store to learn more about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for each in googlesmall_final:\n",
    "    if each[1] == 'PRODUCTIVITY' and counter <= 30:\n",
    "        print(each)\n",
    "        counter += 1\n",
    "\n",
    "print('')\n",
    "counter = 0\n",
    "for each in apple_final:\n",
    "    if each[11] == 'Productivity' and counter <= 30:\n",
    "        print(each)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this quick scan, we can see that the category may not be as promising as initially thought. It is still dominated by a large nubmer of ultimate players with many apps (eg. Google with 10+ productivity apps for each of their Google Docs/Sheets/Slides, etc. Security appears to be a theme on the Android play store but does not transfer well to the Apple store, and thus isn't in line with the agency's strategy. And finally there are VPN apps, which are now a relatively crowded space as well.\n",
    "\n",
    "Photography is another area that appears to be promising across both app stores. Printing out the top 30 apps in each category could provide some insight (done below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for each in googlesmall_final:\n",
    "    if each[1] == 'PHOTOGRAPHY' and counter <= 30:\n",
    "        print(each)\n",
    "        counter += 1\n",
    "\n",
    "print('')\n",
    "counter = 0\n",
    "for each in apple_final:\n",
    "    if each[11] == 'Photo & Video' and counter <= 30:\n",
    "        print(each)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appear to be a large number of apps focused on helping individuals edit their photos. This could be promising as it scales well in both app stores, has no highly dominant players which have captured the bulk of the market, and is likely to continue to grow as a category as individuals increasingly turn to their phone cameras as their primary capture device. Pending further analysis, I would suggest that the agency explore the opportunity to build an app in this category."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
