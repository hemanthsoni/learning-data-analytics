{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profitable App Profiles\n",
    "### Hemanth Soni, June 2020\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction and Overview\n",
    "\n",
    "The goal of this project is to identify the most profitable app profiles in the store. This should help our agency identify where we should focus our development effort. In order to ensure only relevant data is analyzed, the characteristics of the agency need to be kept in mind:\n",
    "* Only builds free apps (no paid apps)\n",
    "* Only builds apps for the English-speaking world (no foreign-language apps)\n",
    "\n",
    "Typically, I wouldn't want to exclude data outside of this profile (as I may find that those excluded categories / formats are actually the most lucrative) but for the purposes of this exercise I'll take those constraints for granted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets\n",
    "\n",
    "First, I'm going to start by importing a few datasets. The tutorial I am following provides two:\n",
    "* [9660 Android apps](https://www.kaggle.com/lava18/google-play-store-apps)\n",
    "* [7195 iOS apps](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps)\n",
    "\n",
    "Separately, I was able to find a [third much larger dataset of Android apps on Kaggle](https://www.kaggle.com/gauthamp10/google-playstore-apps?select=Google-Playstore-Full.csv). It has the same fields available in the provided Android dataset, so I'm going to also include this in the analysis. The larger dataset should allow for more granular insights into the Android market. Unfortunately, a similar larger dataset couldn't be found for the Apple app store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "#The small Google dataset\n",
    "open_file = open('apps_datasets/google_small.csv', encoding='utf8')\n",
    "read_file = reader(open_file)\n",
    "googlesmall = list(read_file)\n",
    "googlesmall_header = googlesmall[0]\n",
    "googlesmall_table = googlesmall[1:]\n",
    "\n",
    "#The large Google dataset\n",
    "open_file = open('apps_datasets/google_large.csv', encoding='utf8')\n",
    "read_file = reader(open_file)\n",
    "googlelarge = list(read_file)\n",
    "googlelarge_header = googlelarge[0]\n",
    "googlelarge_table = googlelarge[1:]\n",
    "\n",
    "#The Apple dataset\n",
    "open_file = open('apps_datasets/apple.csv', encoding='utf8')\n",
    "read_file = reader(open_file)\n",
    "apple = list(read_file)\n",
    "apple_header = apple[0]\n",
    "apple_table = apple[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make this data easier to explore, I first wrote a function that makes it easier to 'peek' into a dataset in a readable way. This function lets me print any number of rows from each of the datasets and get a view into the datasets total number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of first 5 rows in database\n",
      "\n",
      "\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Coloring book moana', 'ART_AND_DESIGN', '3.9', '967', '14M', '500,000+', 'Free', '0', 'Everyone', 'Art & Design;Pretend Play', 'January 15, 2018', '2.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite ‚Äì FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "Number of columns = 13\n",
      "Number of rows = 10841\n",
      "----------------------------------------\n",
      "Overview of first 5 rows in database\n",
      "\n",
      "\n",
      "['App Name', 'Category', 'Rating', 'Reviews', 'Installs', 'Size', 'Price', 'Content Rating', 'Last Updated', 'Minimum Version', 'Latest Version', '', '', '', '']\n",
      "\n",
      "\n",
      "['DoorDash - Food Delivery', 'FOOD_AND_DRINK', '4.548561573', '305034', '5,000,000+', 'Varies with device', '0', 'Everyone', 'March 29, 2019', 'Varies with device', 'Varies with device', '', '', '', '']\n",
      "\n",
      "\n",
      "['TripAdvisor Hotels Flights Restaurants Attractions', 'TRAVEL_AND_LOCAL', '4.400671482', '1207922', '100,000,000+', 'Varies with device', '0', 'Everyone', 'March 29, 2019', 'Varies with device', 'Varies with device', '', '', '', '']\n",
      "\n",
      "\n",
      "['Peapod', 'SHOPPING', '3.656329393', '1967', '100,000+', '1.4M', '0', 'Everyone', 'September 20, 2018', '5.0 and up', '2.2.0', '', '', '', '']\n",
      "\n",
      "\n",
      "['foodpanda - Local Food Delivery', 'FOOD_AND_DRINK', '4.107232571', '389154', '10,000,000+', '16M', '0', 'Everyone', 'March 22, 2019', '4.2 and up', '4.18.2', '', '', '', '']\n",
      "\n",
      "\n",
      "Number of columns = 15\n",
      "Number of rows = 267052\n",
      "----------------------------------------\n",
      "Overview of first 5 rows in database\n",
      "\n",
      "\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "['529479190', 'Clash of Clans', '116476928', 'USD', '0.0', '2130805', '579', '4.5', '4.5', '9.24.12', '9+', 'Games', '38', '5', '18', '1']\n",
      "\n",
      "\n",
      "['420009108', 'Temple Run', '65921024', 'USD', '0.0', '1724546', '3842', '4.5', '4.0', '1.6.2', '9+', 'Games', '40', '5', '1', '1']\n",
      "\n",
      "\n",
      "Number of columns = 16\n",
      "Number of rows = 7197\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def explore_data (dataset, start, end, overview=True, hasHeader=True):\n",
    "    slice = dataset[start:end]\n",
    "    \n",
    "    print('Overview of first ' + str(end-start) + ' rows in database')\n",
    "    print('\\n')\n",
    "    \n",
    "    for each in slice:\n",
    "        print(each)\n",
    "        print('\\n')\n",
    "        \n",
    "    if overview == True:\n",
    "        if hasHeader == True:\n",
    "            print('Number of columns = ' + str(len(dataset[0])))\n",
    "            print('Number of rows = ' + str(len(dataset)-1))\n",
    "            print('-'*40)\n",
    "        else:\n",
    "            print('Number of columns = ' + str(len(dataset[0])))\n",
    "            print('Number of rows = ' + str(len(dataset)))\n",
    "            print('-'*40)\n",
    "            \n",
    "explore_data(googlesmall,0,5)\n",
    "explore_data(googlelarge,0,5)\n",
    "explore_data(apple,0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "\n",
    "### Manually correcting known error\n",
    "\n",
    "Based on a [discussion](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) of one of the datasets, there appears to be a known error in the small Google Play Store dataset. We can correct for this by filling in the data by finding [the app](https://play.google.com/store/apps/details?id=com.lifemade.internetPhotoframe) in the Play Store and filling in the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "# Finding the app based on the comments section and printing it to ensure it matches the expected error row.\n",
    "print(googlesmall[10473])\n",
    "\n",
    "# Printing another row that is known to be fine to understand where the issue lays.\n",
    "print(googlesmall[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing these two outputs, we can see that the \"category\" (index position 1) is missing in the error row. We can correct for this by adding it into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Life Made WI-Fi Touchscreen Photo Frame', 'LIFESTYLE', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "googlesmall[10473].insert(1,'LIFESTYLE')\n",
    "\n",
    "print(googlesmall[10473])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicates\n",
    "\n",
    "Generally, it's a good idea to check for duplicates in the datasets, and remove them if they exist. We will do this as a two step process.\n",
    "1. Check if the database has duplicates\n",
    "2. Remove the duplicates\n",
    "\n",
    "We could theoretically skip step 1, but we'll do it anyways since this is meant to be a learning experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique apps: 7198\n",
      "Number of duplicate apps: 0\n",
      "Number of unique apps: 9661\n",
      "Number of duplicate apps: 1181\n"
     ]
    }
   ],
   "source": [
    "# Initiating lists\n",
    "duplicate_apps = []\n",
    "unique_apps = []\n",
    "\n",
    "# Function to check for duplicates\n",
    "def check_dupes(listname):\n",
    "    for each in listname:\n",
    "        name = each[0]\n",
    "        if name in unique_apps:\n",
    "            duplicate_apps.append(name)\n",
    "        else:\n",
    "            unique_apps.append(name)\n",
    "            \n",
    "    print('Number of unique apps:',len(unique_apps))\n",
    "    print('Number of duplicate apps:',len(duplicate_apps))\n",
    "    \n",
    "    del unique_apps[:]\n",
    "    del duplicate_apps[:]\n",
    "    \n",
    "# Checking each list for duplicates\n",
    "check_dupes(apple)\n",
    "check_dupes(googlesmall)\n",
    "\n",
    "# The check for the large database is disabled as my computer isn't strong enough to run it.\n",
    "# check_dupes(googlelarge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this, we can see that the Apple Store dataset doesn't have any duplicates for us to worry about, but the smaller Google Play Store dataset does. We'll filter through this list and keep only the version of each app with the most reviews (as this suggests the most complete and up-to-date data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating dictionary to store highest-review-count-version of each app\n",
    "reviews_max = {}\n",
    "\n",
    "# Iterating through smaller Google dataset\n",
    "for each in googlesmall[1:]:\n",
    "    name = each[0]\n",
    "    n_reviews = float(each[3])\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    elif name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can check for errors by comparing the expected length of the dictionary vs. the actual length of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The dictionary is the expected size: 9660 entries.\n"
     ]
    }
   ],
   "source": [
    "if int(len(googlesmall_table)-1181) == len(reviews_max):\n",
    "    print ('Success! The dictionary is the expected size:',len(reviews_max),'entries.')\n",
    "else:\n",
    "    print ('Something is wrong.',int(len(googlesmall_table)-1181),'entries were expected, but',len(reviews_max),'were recorded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll use this dictionary to remove the duplicates, keeping the entry version with the greatest number of reviews and entering them into a new table, 'googlesmall_nodupes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating new lists\n",
    "googlesmall_nodupes = []\n",
    "already_added = []\n",
    "\n",
    "# Filling out new lists\n",
    "for each in googlesmall[1:]:\n",
    "    name = each[0]\n",
    "    n_reviews = float(each[3])\n",
    "    \n",
    "    if reviews_max[name] >= n_reviews and name not in already_added:\n",
    "        googlesmall_nodupes.append(each)\n",
    "        already_added.append(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing non-English apps\n",
    "\n",
    "To filter out non-English apps, I'll filter the database for any non-English characters (beyond ASCII code 127)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to check if the passed phrase is fully English\n",
    "def isEnglish(phrase):\n",
    "    \n",
    "    non_english = 0\n",
    "    \n",
    "    for each in phrase:\n",
    "        if ord(each) > 127:\n",
    "            non_english += 1\n",
    "        \n",
    "        if non_english >= 3:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "# Testing this function against several examples\n",
    "# print(isEnglish('Instachat üòú'))\n",
    "# print(isEnglish('Instagram'))\n",
    "# print(isEnglish('Áà±Â•áËâ∫PPS -„ÄäÊ¨¢‰πêÈ¢Ç2„ÄãÁîµËßÜÂâßÁÉ≠Êí≠'))\n",
    "# print(isEnglish('Docs To Go‚Ñ¢ Free Office Suite'))\n",
    "\n",
    "googlesmall_nodupes_eng = []\n",
    "googlelarge_eng = []\n",
    "apple_eng = []\n",
    "\n",
    "for each in googlesmall_nodupes:\n",
    "    name = each[0]\n",
    "    if isEnglish(name):\n",
    "        googlesmall_nodupes_eng.append(each)\n",
    "        \n",
    "for each in googlelarge:\n",
    "    name = each[0]\n",
    "    if isEnglish(name):\n",
    "        googlelarge_eng.append(each)\n",
    "\n",
    "for each in apple:\n",
    "    name = each[1]\n",
    "    if isEnglish(name):\n",
    "        apple_eng.append(each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing paid apps\n",
    "\n",
    "Because the agency is only concerned with free apps, we can use a similar mechanism to the above to remove any apps that are paid. This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8847\n",
      "3203\n"
     ]
    }
   ],
   "source": [
    "# Initializing final lists for each dataset\n",
    "googlesmall_final = []\n",
    "googlelarge_final = []\n",
    "apple_final = []\n",
    "\n",
    "for each in googlesmall_nodupes_eng:\n",
    "    price = each[7]\n",
    "    if price == '0':\n",
    "        googlesmall_final.append(each)\n",
    "        \n",
    "for each in apple_eng:\n",
    "    price = each[4]\n",
    "    if price == '0.0':\n",
    "        apple_final.append(each)\n",
    "\n",
    "print(len(googlesmall_final))\n",
    "print(len(apple_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Data\n",
    "\n",
    "Now that I have my cleaned datasets, I can begin the analysis. To do this in the most useful way possible, I have to consider the launch strategy of the agency, which is as follows:\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to Google Play.\n",
    "2. If the app has a good response from users, develop it further.\n",
    "3. If the app is profitable after six months, build an iOS version of the app and add it to the App Store.\n",
    "\n",
    "The agency has already determined through previous analysis that there is a direct and linear correlation between the number of installs and the revenue generated by the app; thus to maximize profit our goal is to maximize installations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common App Profiles\n",
    "\n",
    "Given that the agency's target is to launch the same app on multiple stores, I can start by identifying the types of applications that are successful in both the Google Play Store and the Apple iOS store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to build a frequency table out of any dataset for a given index number\n",
    "\n",
    "def freq_table(dataset, index):\n",
    "    table = {}\n",
    "    total = 0\n",
    "\n",
    "    for each in dataset:\n",
    "\n",
    "        # Extracting the value at the given index number\n",
    "        value = each[index]\n",
    "\n",
    "        # Checking if value exists in table and either adding to the count or creating the entry\n",
    "        if value in table:\n",
    "            table[value] += 1\n",
    "        else:\n",
    "            table[value] = 1\n",
    "\n",
    "        # Increasing the total count by 1\n",
    "        total += 1\n",
    "\n",
    "        # Initializing a new table to return figures in percentages\n",
    "        table_percent = {}\n",
    "\n",
    "        for each in table:\n",
    "            percentage = table[each] / total * 100\n",
    "            table_percent[each] = percentage\n",
    "\n",
    "        return table_percent\n",
    "\n",
    "# Creating a function that sorts and then prints a given input frequency table\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "\n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ART_AND_DESIGN : 100.0\n",
      "Art & Design : 100.0\n"
     ]
    }
   ],
   "source": [
    "# Creating tables for each of the app stores\n",
    "\n",
    "display_table(googlesmall_final,1)\n",
    "display_table(googlesmall_final,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
